{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import pickle\n",
    "import gzip\n",
    "import logging\n",
    "\n",
    "tf.get_logget().setLevel(logging.ERROR)\n",
    "\n",
    "TRAINING_FILE_DIR = \"\"\n",
    "OUTPUT_FILE_DIR = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4894771",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_FILE_DIR + \"captions_train2014\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "image_dict = {}\n",
    "for image in data[\"images\"]:\n",
    "    image_dict[image[\"id\"]] = [image[\"file_name\"]]\n",
    "    for anno in data[\"annotations\"]:\n",
    "        image_dict[anno[\"image_id\"]].append(anno[\"caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19(weights=\"imagenet\")\n",
    "model.summary()\n",
    "model_new = Model(inputs=model.input, outputs=model.get_layer(\"block_conv4\").output)\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(image_dict.keys()):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Progress: \" + str(i) + \" images processed\")\n",
    "    item = image_dict.get(key)\n",
    "    filename = TRAINING_FILE_DIR + \"train2014/\" + item[0]\n",
    "\n",
    "    image = load_img(filename)\n",
    "    width = image.size[0]\n",
    "    height = image.size[1]\n",
    "\n",
    "    if height > width:\n",
    "        image = load_img(filename, target_size=(int(height / width * 256)))\n",
    "    else:\n",
    "        image = load_img(filename, target_size=(256, int(width / height * 256)))\n",
    "\n",
    "    width = image.size[0]\n",
    "    height = image.size[1]\n",
    "    image_np = img_to_array(image)\n",
    "\n",
    "    h_start = int((height - 224) / 2)\n",
    "    w_start = int((width - 224) / 2)\n",
    "    image_np = image_np[h_start : h_start + 224, w_start : w_start + 224]\n",
    "\n",
    "    image_np = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "    x = preprocess_input(image_np)\n",
    "    y = model_new.predict(x)\n",
    "\n",
    "    save_filename = OUTPUT_FILE_DIR + item[0] + \".pickle.gzip\"\n",
    "    pickle_file = gzip.open(save_filename, \"wb\")\n",
    "    pickle.dump(y[0], pickle_file)\n",
    "    pickle_file.close()\n",
    "\n",
    "save_filename = OUTPUT_FILE_DIR + \"caption_file.pickle.gz\"\n",
    "pickle_file = gzip.open(save_filename, \"wb\")\n",
    "pickle.dump(image_dict, pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Dense,\n",
    "    Attention,\n",
    "    Concatenate,\n",
    "    GlobalAveragePooling2D,\n",
    "    Reshape,\n",
    ")\n",
    "from tensorflow.keras.model import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
